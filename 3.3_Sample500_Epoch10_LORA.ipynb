{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVk5XL5cErVa",
        "outputId": "03ecf11a-3333-4196-9558-eb51ac55a022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsaZFg5NCp3K",
        "outputId": "8bc49241-ff88-4aa0-f4e2-ee6c2d3dc10d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.23.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ravi4\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.1 -> 24.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install the datasets library\n",
        "! pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bB5VCz_cB2sH"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, DataCollatorForLanguageModeling\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RopgfU7CH9i"
      },
      "source": [
        "**2- DEFINE LORA Layer**\n",
        "\n",
        "Define the custom Low-Rank Adaptation (LoRA) layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e9PSF8yZB4nB"
      },
      "outputs": [],
      "source": [
        "# Define the LoRA Layer\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, input_dim, rank=4):\n",
        "        super(LoRALayer, self).__init__()\n",
        "        self.rank = rank\n",
        "        self.A = nn.Parameter(torch.randn(input_dim, rank))\n",
        "        self.B = nn.Parameter(torch.randn(rank, input_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + torch.matmul(torch.matmul(x, self.A), self.B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw-apTj8WnL5"
      },
      "source": [
        "3. Modify GPT-2 to Include LoRA Layers\n",
        "Create a new class to modify the GPT-2 model to include the LoRA layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nQvv4aOOB426"
      },
      "outputs": [],
      "source": [
        "# Modify GPT-2 to include LoRA layers\n",
        "class GPT2WithLoRA(nn.Module):\n",
        "    def __init__(self, model_name='gpt2', rank=4):\n",
        "        super(GPT2WithLoRA, self).__init__()\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "        self.rank = rank\n",
        "        self.add_lora_layers()\n",
        "\n",
        "    def add_lora_layers(self):\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                input_dim = module.in_features\n",
        "                lora_layer = LoRALayer(input_dim, self.rank)\n",
        "                module.add_module('lora', lora_layer)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        return self.model(input_ids, attention_mask=attention_mask, labels=labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv7im33rEb7L"
      },
      "source": [
        "4. Load Pre-trained Model and Tokenizer\n",
        "Load the pre-trained GPT-2 model and tokenizer, and set the padding token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqtPU1DoOJ_-",
        "outputId": "f6d2a4c1-70ec-4582-8940-4604d04226b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PIA-SZUuB5Ei"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Set EOS token as pad token\n",
        "model = GPT2WithLoRA('gpt2').to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuv3jhkwEfyi"
      },
      "source": [
        "5. Define Optimizer and Loss Function\n",
        "Set up the optimizer and loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5QSVW2YXB5Lq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ravi4\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI5LFeCYE11Y"
      },
      "source": [
        "6. Load and Prepare Dataset\n",
        "Load the WikiText-103 dataset, sample a subset, and prepare it for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E-q5SUB3B5SJ"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3ce94ecda5647e8980116699bbcab7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/722k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5318845510a40bebf27ea1a3c2e337b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/156M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a51e122559c431ea70f247ac8d2099f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/156M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12dd7e318d704958a67d2b16cce2a8da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/655k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29921b34302044ed9ab3b322eda245ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "755a2deaf90d4b90addd6efcccc5e382",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ef30a033bf44a6b97048a0a2c843ece",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load WikiText-103 dataset\n",
        "wikitext = load_dataset('wikitext', 'wikitext-103-v1')\n",
        "\n",
        "# Convert the dataset to a list of dictionaries\n",
        "train_samples = [sample for sample in wikitext['train']]\n",
        "\n",
        "# Use a small sample of 500 rows for quick testing\n",
        "sample_size = 500\n",
        "train_sampled = random.sample(train_samples, sample_size)\n",
        "train_df = pd.DataFrame(train_sampled)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fozgRUBXaN4n",
        "outputId": "052038b0-e4a3-4303-acba-7d3929eaf8d5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 270,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 186,\n        \"samples\": [\n          \" In April 1987 , Bakshi set up a meeting with Judy Price , the head of CBS 's Saturday morning block . Three days before the meeting , Bakshi , Kricfalusi , Naylor , Tom Minton , Eddie Fitzgerald and Jim Reardon met to brainstorm . Bakshi remembers , \\\" My car was packed to the windows . Judy was my last stop before driving cross country back to New York to my family . \\\" Price rejected Bakshi 's prepared pitches , but asked what else he had . He told her that he had the rights to Mighty Mouse , and she agreed to purchase the series . However , Bakshi did not own the rights and did not know who did . While researching the rights , he learned that CBS had acquired the entire Terrytoons library in 1955 and forgotten about it . According to Bakshi , \\\" I sold them a show they already owned , so they just gave me the rights for nothin ' ! \\\" \\n\",\n          \" = = = Memorable NBA Finals games = = = \\n\",\n          \" = = Chart performance = = \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-183bdfd8-a644-49db-a177-9eb2f2fdf5fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>In accordance with the Marxist doctrine that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Some women trained as gymnasts and dancers , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>= = Personnel = = \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>The song created controversy over the writing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>= = Parks and recreation = = \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Irene also caused severe agricultural damage ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>= = Lyrics = = \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-183bdfd8-a644-49db-a177-9eb2f2fdf5fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-183bdfd8-a644-49db-a177-9eb2f2fdf5fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-183bdfd8-a644-49db-a177-9eb2f2fdf5fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-26e27ba5-7924-4bca-ab0e-f9717b82cc51\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26e27ba5-7924-4bca-ab0e-f9717b82cc51')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-26e27ba5-7924-4bca-ab0e-f9717b82cc51 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9c309b58-bb50-4bd3-916d-0e20db36de08\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9c309b58-bb50-4bd3-916d-0e20db36de08 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  text\n",
              "192   In accordance with the Marxist doctrine that ...\n",
              "4     Some women trained as gymnasts and dancers , ...\n",
              "16                                = = Personnel = = \\n\n",
              "115   The song created controversy over the writing...\n",
              "138                    = = Parks and recreation = = \\n\n",
              "..                                                 ...\n",
              "8     Irene also caused severe agricultural damage ...\n",
              "117                                                   \n",
              "238                                  = = Lyrics = = \\n\n",
              "132                                                   \n",
              "116                                                   \n",
              "\n",
              "[270 rows x 1 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXXaOC5ePbvY"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr2k5NwBE7ZK"
      },
      "source": [
        "7. Prepare Dataset for the Model\n",
        "Prepare the dataset using a custom TextDataset class and a data loader with padding handled by a data collator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uloZMlpmB5Xr"
      },
      "outputs": [],
      "source": [
        "# Prepare the dataset for the model\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]['text']\n",
        "        inputs = self.tokenizer(text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
        "        input_ids = inputs['input_ids'].squeeze().long()  # Ensure LongTensor\n",
        "        attention_mask = inputs['attention_mask'].squeeze().long()  # Ensure LongTensor\n",
        "        return input_ids, attention_mask, input_ids\n",
        "\n",
        "# Create DataLoader for training and validation datasets\n",
        "train_dataset = TextDataset(train_df, tokenizer)\n",
        "val_dataset = TextDataset(val_df, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "J6ACuy8II948"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Custom collator function to handle padding and formatting\n",
        "def custom_collate_fn(batch):\n",
        "    input_ids = [item[0] for item in batch]\n",
        "    attention_masks = [item[1] for item in batch]\n",
        "    labels = [item[2] for item in batch]\n",
        "\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id).long()\n",
        "    attention_masks = torch.nn.utils.rnn.pad_sequence(attention_masks, batch_first=True, padding_value=0).long()\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id).long()\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_masks,\n",
        "        'labels': labels\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGVfnG7GdCRj"
      },
      "source": [
        "It is important that we increase batch_size from 4 to 16 for better results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jk5XnEqLdDUL"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wuetXsyFCcE"
      },
      "source": [
        "8. Training Loop\n",
        "Train the model with LoRA for a specified number of epochs and print the average loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5k4RMutFDRr",
        "outputId": "c5879d89-bd59-44ab-af24-f143fd310641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.6147\n",
            "Epoch 1, Validation Loss: 0.2732\n",
            "Epoch 2, Loss: 0.5267\n",
            "Epoch 2, Validation Loss: 0.2718\n",
            "Epoch 3, Loss: 0.5297\n",
            "Epoch 3, Validation Loss: 0.2964\n",
            "Epoch 4, Loss: 0.6990\n",
            "Epoch 4, Validation Loss: 0.2965\n",
            "Epoch 5, Loss: 0.5706\n",
            "Epoch 5, Validation Loss: 0.2849\n",
            "Epoch 6, Loss: 0.5355\n",
            "Epoch 6, Validation Loss: 0.2807\n",
            "Epoch 7, Loss: 0.4948\n",
            "Epoch 7, Validation Loss: 0.2776\n",
            "Epoch 8, Loss: 0.4778\n",
            "Epoch 8, Validation Loss: 0.2755\n",
            "Epoch 9, Loss: 0.4686\n",
            "Epoch 9, Validation Loss: 0.2748\n",
            "Epoch 10, Loss: 0.4506\n",
            "Epoch 10, Validation Loss: 0.2737\n"
          ]
        }
      ],
      "source": [
        "# Training loop for the model with LoRA\n",
        "model.train()\n",
        "num_epochs = 10\n",
        "patience = 2\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Skip empty batches\n",
        "        if input_ids.size(0) == 0 or input_ids.size(1) == 0:\n",
        "            continue\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Skip empty batches\n",
        "            if input_ids.size(0) == 0 or input_ids.size(1) == 0:\n",
        "                continue\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGbkYjoUFGOS"
      },
      "source": [
        "9. Save the Model\n",
        "Save the fine-tuned model and tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Jv1ufZ9wFIAj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the model's state dictionary\n",
        "\n",
        "torch.save(model.state_dict(), 'gpt2_with_lora_state_dict.pth')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGFgPY3pLSPN",
        "outputId": "f7737b10-ae89-4c62-dec2-40504554dcab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('gpt2_with_lora_tokenizer/tokenizer_config.json',\n",
              " 'gpt2_with_lora_tokenizer/special_tokens_map.json',\n",
              " 'gpt2_with_lora_tokenizer/vocab.json',\n",
              " 'gpt2_with_lora_tokenizer/merges.txt',\n",
              " 'gpt2_with_lora_tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the tokenizer\n",
        "\n",
        "tokenizer.save_pretrained('gpt2_with_lora_tokenizer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baNKzKGuFJ_H"
      },
      "source": [
        "Explanation:\n",
        "-Imports: Import necessary libraries for model handling, dataset loading, and training.\n",
        "\n",
        "-LoRA Layer: Define a custom layer that adds low-rank adaptation to the model.\n",
        "\n",
        "-Model Modification: Modify GPT-2 to include the LoRA layers.\n",
        "\n",
        "-Load Model: Load the pre-trained GPT-2 model and set the padding token.\n",
        "\n",
        "-Optimizer and Loss: Set up the optimizer and loss function for training.\n",
        "\n",
        "-Dataset Loading: Load and sample the WikiText-103 dataset for quick testing.\n",
        "\n",
        "-Dataset Preparation: Prepare the dataset and data loader with padding handled by a data collator.\n",
        "\n",
        "-Training Loop: Train the model and print the loss for each epoch.\n",
        "\n",
        "-Save Model: Save the fine-tuned model and tokenizer for later use.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
